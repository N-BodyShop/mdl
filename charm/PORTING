Issues for porting MDL to charm:

First try: (revision 1.3)

This is not that different than, say, an MPI version.  Out of order
delivery messages was the one thing we had to deal with.  Cache
flushes were a particular problem since the barrier message could be
delivered before all the flush messages were processed.

revision 1.4: the flush problem was fixed by creating a "FlushAll"
message, where all flushes back to a single processor can be done at
once.  This can then be acknowledged, and solves the out-of-order
message problem.  It would be a good idea to implement this on other
ports.

4/03:
Attempt to use NodeGroups so that all processors on an SMP node can
share their cache.  This also means that processors on a single node
can use shared memory to get at each others data.  First issue: shared
memory is SLOWER than individual processors on a single node.  It
seems there is a problem with threads stumbling over each other.  One
telling problem is that removing CthYield() from mdlCacheCheck speeds
up the shared memory execution, but slows down the non-shared
execution.

5/03: I am now using "CmiDeliverMsgs()".  This helps the non-threaded version
significantly.  I am now pretty sure that part of the slowdown seen above is
compilers fault: the mis-aligned stack problem would show up in the threaded
version but not the single thread version.

Summary of cache architecture:

For readonly cache: if it is on node, simply use shared memory.  Off node
accesses are held in a cache that is shared by all processes on a node.  Each
line has a "bFetching" bit to indicate that a line has been requested, but
hasn't been returned.  This allows more processes to be issuing requests at
once.

For combining cache: all requests (even on-node) end up in the cache.  The
standard line locking is supplemented by the processor who has it locked.
If another processor has the line locked then the line request is REISSUED!
This means there can be multiple copies of the same line in the cache.  This
is OK since it all gets combined in the end.

8/03: Changes from the above: a request for a locked line is not
reissued, but a new copy of the line is made in the cache from the old
line.

After a bit of frustration the Node-Aware version finally works.

Things that had to be changed.
1) I needed to lock in waitCache since any processor on a nodegroup could
get the Cache reply.
2) An extra message needs to be sent to the appropriate processor to call
CthAwaken().

Things that could make it better:
The mapping between array elements and nodes needs to be better.  It would be
nice to have:
1) a way to quickly tell if an element is on my node.
2) Even better, a way to tell which node an array belongs to.
3) Need to know the number of array elements on this node.
4) A way of ranking the array elements on a node.

This is in addition to the mapping from array element to processor.

8/28: Suggestions from Sanjay:

- Tom's Nodegroup-aware MDL works; but not with multiple
array elements per processor.  One key trick for
supporting multiple array elements per processor is to
have each array element "register" itself with the
local nodegroup during the array element constructor,
and to deregister during the destructor.  This lets the
nodegroup itself keep a list of local array elements.

